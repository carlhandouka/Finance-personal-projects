{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bc2d2f",
   "metadata": {},
   "source": [
    "# Portfolio Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc284eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cbb81",
   "metadata": {},
   "source": [
    "# Batches selection (not important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f95ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset, batch_size, seq_length, deltat_in):\n",
    "    n = dataset.shape[0]\n",
    "    time_steps = dataset.shape[1]\n",
    "    idx = np.random.choice(time_steps - seq_length, batch_size)\n",
    "\n",
    "    '''TODO: construct a list of input sequences for the training batch'''\n",
    "    input_batch = [dataset[i:i + seq_length] for i in idx]\n",
    "\n",
    "    '''TODO: construct a list of output sequences for the training batch'''\n",
    "    output_batch = [dataset[i + deltat_in:i + seq_length + deltat_in] for i in idx]\n",
    "\n",
    "    # Convert the input and output batches to tensors\n",
    "    x_batch = torch.tensor(input_batch, dtype=torch.long)\n",
    "    y_batch = torch.tensor(output_batch, dtype=torch.long)\n",
    "\n",
    "    return x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c8a17",
   "metadata": {},
   "source": [
    "# Lag-transformation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1147e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagTransform(nn.Module):\n",
    "    def __init__(self, theta, t, input):\n",
    "        super(LagTransform, self).__init__()\n",
    "        self.t = t\n",
    "        self.theta = theta\n",
    "        self.input = input\n",
    "\n",
    "    def hyperbolic_weighting(self, theta, t):\n",
    "        alpha= theta[0] * t**(-theta[1])\n",
    "        return alpha\n",
    "\n",
    "    def saturating_exponential_threshold(self, theta, t):\n",
    "        beta= theta[2] - theta[3]*np.exp(-theta[4]*t)\n",
    "        return beta\n",
    "\n",
    "\n",
    "    def forward(self, theta: torch.Tensor, t: torch.Tensor, input : torch.Tensor):\n",
    "        return self.hyperbolic_weighting(theta,t) / self.saturating_exponential_threshold(theta,t) * np.tanh(self.saturating_exponential_threshold(theta,t) * input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7e01f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LagTransform.forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y=\u001b[43mLagTransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[31mTypeError\u001b[39m: LagTransform.forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "y=LagTransform.forward(torch.tensor([0.,0.5,1.0,0.5,0.5]), torch.tensor(1.0), torch.tensor([1.0,2.0,3.0]))\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
